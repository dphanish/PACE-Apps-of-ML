{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:24pt; text-decoration:underline; font-weight:bold; color:#003057; text-align:center\">\n",
    "    PACE - Applications of Machine Learning\n",
    "</p>\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "        <a href = \"mailto: dnagendra3@gatech.edu\"><b>Deepa Phanish, PhD</b></a> : <a href = \"https://pace.gatech.edu\" target = \"_blank\"><b>PACE, Georgia Tech</b></a> <br>\n",
    "    <a href = \"mailto: ajezghani3@gatech.edu\"><b>Aaron Jezghani, PhD</b></a> : <a href = \"https://pace.gatech.edu\" target = \"_blank\"><b>PACE, Georgia Tech</b></a> <br>\n",
    "    <a href = \"mailto: chris_blanton@ncsu.edu\"><b>Chris Blanton, PhD</b></a> : <a href = \"https://www.lib.ncsu.edu\" target= \"_blank\"><b>Research Consulting, NCSU</b></a>\n",
    "    \n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color=B3A369><u><b>Introduction</b></u></font>\n",
    "\n",
    "<br>\n",
    "<center><font size=4><i>[Machine Learning is a] field of study that gives computers the ability to learn without being explicitly programmed.</i> <br> --- Arthur Samuel, 1959</font></center>\n",
    "\n",
    "Learning means the performance should improve with experience! Machine learning has existed for decades; however, until recently, computing power and data storage were too limited to allow machines to solve many problems in the field effectively. Advances in speed and density have taken machine learning from an abstract idea to the forefront of scientific research across many domains, including:\n",
    "- Bioinformatics\n",
    "- Molecular dynamics\n",
    "- Astrophysics\n",
    "- Signal processing\n",
    "- Health data analytics\n",
    "- Finance and marketing\n",
    "- Urban planning\n",
    "- ...and many more\n",
    "\n",
    "The volume of data being generated and made available for research is rapidly increasing, and while the technology is constantly being reconsidered to keep up, the challenge of meaningfully utilizing it is becoming ever more present. Even if we ignore the challenges of human bias, the efficiency of humans in reviewing data remains \n",
    "\n",
    "<font size=4 color=B3A369><b>Spam Filters: The Traditional Way</b></font>\n",
    "\n",
    "1. We want to start by identifying some common features in spam emails; these could be:\n",
    "    - phrases (\"4U\", \"one simple trick\", \"aliens\", \"lottery\"), \n",
    "    - questionable domains (\"google.asdqwkjf92.ohno\", \"definitely-not-stealing-your-info.org\"),\n",
    "    - mismatches in sender's name/email (\"Mary Smith from aaron.aaron@itsascam.net\"),\n",
    "    - etc.\n",
    "2. We would write some rules to capture these bits\n",
    "    - You may have already done this for your school/work emails to sort by topic!\n",
    "3. We then execute the email rules to test their validity\n",
    "    - We need to identify correctness, including false positives (good emails mislabeled as spam) and false negatives (spam emails that were missed by our rules)\n",
    "4. We update our rules accordingly, and repeat until we're satisfied.\n",
    "    - Note that as new approaches are deployed, we have to identify and define new features to update our filter.\n",
    "\n",
    "<img src=\"image/traditional-programming.png\" alt=\"Traditional Programming\" width=\"600\"> \n",
    "\n",
    "<font size=4 color=B3A369><b>Spam Filters: Using Machine Learning</b></font>\n",
    "\n",
    "1. We need a reasonably large collection of emails that have been labeled as spam or not spam.\n",
    "    - The dataset may have defined characteristics (sender, message length, domain, etc.), or it may not, in which case we have to define our own.\n",
    "    - Additionally, we can always define additional fields from existing data through a process known as **feature engineering** (e.g., _x_ and _y_ coordinates might be better presented as polar coordinates for data centered around some location).\n",
    "2. We choose an algorithm that can consider the input characteristics and the categorization to determine which emails are spam and which are not.\n",
    "    - There are numerous existing algorithms (linear/logistic regression, neural networks, nearest neighbor, etc.) that can be modified, or a new algorithm can be defined (this is a very active research area after all!).\n",
    "3. We divide the dataset into training and test subsets, typically through some form of random selection.\n",
    "    - Different algorithms perform differently depending on the data, so we want to ascertain our model's efficacy before deploying it in the wild.\n",
    "    - Because of the underlying statistcs used in ML, it can often be helpful to explore resampling in an effort to assess the validity of our model.\n",
    "4. We tune our algorithm until we reach the desired level of accuracy, and then we deploy the model in the real world.\n",
    "    - Unlike the traditional method, machine learning has the ability to adapt to novel spam data - the model might need retraining, but we can in theory still use the same algorithm (this is what you're doing when you provide feedback on applications like Google Maps).\n",
    "\n",
    "<img src=\"image/machine_learning.png\" alt=\"Machine Learning\" width=\"600\"> \n",
    "\n",
    "<font size=5 color=B3A369><u><b>Using the Correct Tools...Correctly</b></u></font>\n",
    "\n",
    "There's often a difficult progression with ML projects from proof-of-concept to large-scale application, and a little foresight can reduce headaches significantly. Fortunately, framework such as TensorFlow and PyTorch significantly ease the transition from CPU to GPU, to the point where developing directly for GPU training is accessible. However, issues with scaling, either in terms of data or process distribution, can often manifest as one increases the scope of their project. Additionally, hardware-specific optimizations may be missed as code is migrated to new hardware, especially if outdated versions of computational libraries are used.\n",
    "\n",
    "Based on the hardware you've chosen to use, it's always worthwhile to explore the vendor's recommended settings. Since we'll be using Intel CPUs, we can take a look at [their recommendations](https://www.intel.com/content/www/us/en/developer/articles/technical/maximize-tensorflow-performance-on-cpu-considerations-and-recommendations-for-inference.html):\n",
    "\n",
    "- KMP_AFFINITY=granularity=fine,verbose,compact,1,0 <font color=008080><em>#Bind OpenMP threads to physical cores</em></font>\n",
    "- TF_ENABLE_ONEDNN_OPTS=1 <font color=008080><em>#Enable IntelÂ® oneAPI Deep Neural Network Library capabilities</em></font>\n",
    "- OMP_NUM_THREADS=${PBS_NP} <font color=008080><em>#One thread per physical core</em></font>\n",
    "- KMP_BLOCKTIME=0 <font color=008080><em>#Sets time that threads wait before sleeping</em></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_AFFINITY']=\"granularity=fine,verbose,compact\" #No hyper-threading\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS']=\"1\" #OneDNN CPU optimizations\n",
    "os.environ['OMP_NUM_THREADS']=os.getenv('PBS_NP') #Single hardware thread per core\n",
    "os.environ['KMP_BLOCKTIME']=\"0\" #empirically test the correct value - >0 for non-OMPthreaded code embedding "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color=B3A369><u><b>Practical Example: ML in Medicine</b></u></font>\n",
    "\n",
    "When developing a machine learning workflow, it can be tempting to focus solely on the machine learning algorithm and model refinement. However, before that aspect can be considered, there are other challenges:\n",
    "- Where do we get the data?\n",
    "- Is the data formatted appropriately for the system?\n",
    "- What framework/hardware will be used?\n",
    "\n",
    "To explore these issues, we can use a standard training example from the community: automated breast cancer detection. As you may be aware, breast cancer is one of the most common cancers among women worldwide. Early diagnosis of breast cancer can greatly increase the outlook for patients, but accurate diagnosis can be a challenge as it requires expert analysis, and thus areas lacking in experts can be greatly affected.\n",
    "\n",
    "The Wisconsin breast cancer dataset consists of 30 parameters obtained via analysis of fine needle aspiration (FNA) biopsy of breast masses. The data describes characteristics of the cell nuclei in the image. This dataset has been previously studied in several papers, including [Breast Cancer Detection with Reduced Feature Set](https://www.hindawi.com/journals/cmmm/2015/265138/). Because each mass is labeled as benign or malignant, we can use the data to explore the application of machine learning techniques and gain insights into the viability of ML for real-world applications such as this.\n",
    "\n",
    "<font size=4 color=B3A369><b>Our Plan of Action</b></font>\n",
    "\n",
    "In this workshop, we will look at an example workflow on one of PACE's instructional clusters using CPUs for analysis. In short, we will use our labeled dataset of thirty features to train a classifier that will attempt to label new data as either benign or malignant. The steps we will take are as follows:\n",
    "1. Import the necessary libraries to explore/analyze our data and develop our model.\n",
    "2. Acquire our data and transform it to a useable form.\n",
    "3. Explore our data and garner any initial insights that might help us in our efforts.\n",
    "4. Prepare the data for training.\n",
    "5. Split the data into training and test subsets. !! This needs to be done before data prep to avoid information leakage\n",
    "6. Pick our ML algorithm and train our model.\n",
    "7. Test and evaluate our model to further explore the training process.\n",
    "\n",
    "<font size=5 color=B3A369><u><b>1. Import Libraries</b></u></font>\n",
    "\n",
    "There are numerous libraries that can be utilized in an ML project - we'll try to touch on several in this workshop to provide broader familiarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python --version\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "import sklearn\n",
    "#show images inline with code block\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes, it is helpful to check versions of packages to verify capability/compatibility:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"TensorFlow version: {}\".format(tf.__version__))\n",
    "print(\"Eager execution is: {}\".format(tf.executing_eagerly()))\n",
    "print(\"Keras version: {}\".format(tf.keras.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.config.list_physical_devices('GPU') )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Eager execution** is enabled by default (and was meant to tackle a big issue in TFv1). It:\n",
    "- evaluates operations immediately\n",
    "- returns actual values rather than computational graphs to be run later\n",
    "- calculates the values of tensors as they occur\n",
    "\n",
    "Broadly speaking, it's meant to make things simpler and more accessible for beginners.\n",
    "\n",
    "*However*, disabling this feature provides an opportunity for more optimization, as you can extract tensor computations and build a more effecient graph before proceeding. Thus, more advanced users may desire to run in this mode instead - for today, though, we'll keep it enabled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color=B3A369><u><b>2. Acquire/Transform Data</b></u></font>\n",
    "\n",
    "There are numerous sources for ML training sets, including directly from the Python libraries themselves. Picking one from the ML framework you're using has the advantage that it is usually formatted correctly, but since we want to explore the data transformation component of our workflow, we'll take our dataset from the SciKit-Learn datasets. In real-world, you may need to do plenty of data clean-up before having a structured dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer # Loading the breast cancer from a standard datasource within SciKit\n",
    "cancer = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the data to get a better understanding of how it is formatted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cancer #This is a dictionary like object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the data uses human-readable characters, it's not formatted for easy reading by a human. We can manipulate it to change that!\n",
    "\n",
    "First, let's start by getting the names of the fields:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this Python dictionary, we can focus on a single component of the dataset rather than dumping a block of information. For example, we can read the data description:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cancer['DESCR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we want to develop a classifier, ultimately we need to explore the labels, or targets, for the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cancer['target'])\n",
    "print(cancer['target'].shape) \n",
    "print(cancer['target'].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the target data is presented as a binary encoding (either 0 or 1). If we want to know which value maps to which label, we can use the \"target_names\" field:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cancer['target_names'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the array is 0-indexed, that means a value of '0' maps to 'malignant' and a value of '1' corresponds to 'benign'. \n",
    "\n",
    "Carrying on, the features of the set can be found by looking at the 'features_names' entry:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cancer['feature_names'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color=B3A369><b>Pandas Dataframes</b></font>\n",
    "\n",
    "Since the data exhibits a fair amount of variety, we want to store it into an appropriate object. Pandas dataframes offer an excellent solution - they are data structures that provide labeled axes for heterogeneous data types, so they do exactly what we want! To convert our dataset to a dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cancer = pd.DataFrame(np.c_[cancer['data'],cancer['target']],columns=np.append(cancer['feature_names'],['target']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, TensorFlow does not allow spaces in feature names, so we'll have to fix that. This can be accomplished by looping over our dataset, replacing the spaces with a suitable character (e.g. an underscore), and updating our dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in df_cancer.keys():\n",
    "    newkey = key.replace(\" \", \"_\")\n",
    "    df_cancer.rename(index=str,columns={key:newkey},inplace=True)\n",
    "print(df_cancer.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the nice functionality of a dataframe to look at the beginning of our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cancer.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write command to print the first few records\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...or the end of it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "#Write command to print the last few records\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we're feeling wild, we can even request more than 5 rows at a time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Write command to print only last 7 records\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the data pre-processing steps you may need to do at this stage:\n",
    "* Impute missing data - Fill missing data with mode and impute nulls with medians\n",
    "* Delete duplicate records\n",
    "* Drop irrelevant (all-to-one and one-to-all mapping) features\n",
    "* One-hot encoding for Categorical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color=B3A369><u><b>3. Explore Data</b></u></font>\n",
    "\n",
    "Often it is assumed that with all the data, everything can be known. As it turns out, though, gathering the data isn't the only challenge of this approach; redundancy in the data and too many features can lead to inefficiencies in training. For example, in our dataset are there multiple descriptions of the same property that don't provide a additional insights? Or perhaps, are there any data points that seem purely superfluous?\n",
    "\n",
    "The challenge, of course, is how can we meaningfully pare down our data. Since we want to determine the target with our classifier, we can start by exploring how strongly correlated each feature is with the target values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking summary statistics\n",
    "df_cancer.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cancer.corr()['target'].sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above can give us insights into the impact of any one feature in terms of determining the target value, but lacks any information about data redundancies that may exist between different features. \n",
    "\n",
    "<font size=4 color=B3A369><b>Dataset Visualization</b></font>\n",
    "\n",
    "To explore the relationships between variables, we can utilize a correlation matrix heatmap, where the color indicates how strongly correlated each pair of features is. Values close to -1 show a strong negative correlation (one variable increases as the other decreases), while values close to +1 show a strong positive correlation (both increase or decrease together).\n",
    "\n",
    "While we can use other libraries to generate this heatmap, the Seaborn library provides a very simple, dataframe-compatible function to achieve our goal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10)) #default size can be difficult to view\n",
    "ax = sns.heatmap(df_cancer.corr(),annot=True) \n",
    "#bottom, top = ax.get_ylim()  # This is because of an issue in matplotlib < v3.1.2. \n",
    "#ax.set_ylim(bottom+0.5, top-0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is tempting to use all the features in a haphazard way. Designing the right set of features is where the genius lies! In our case, we see several parameters, such as the size of the cells to have multiple types of measurements. It is often advanatageous to try to minimize the number of features because of this and computational expense. \n",
    "\n",
    "Thinking about this in a mathematical sense, the features do not necessarily form a orthogonal basis set. This can lead to degenerate answers which may complicate the optimization process and either lead to a local extrema or failure of convergence. **This is in general terms of optimization, not strictly ML terms.** Having dependent features can lead to numerically unstavle solutions.\n",
    "\n",
    "As related and practical matter, the large the feature set, the more expensive the calcuation is. By reducing the number of features, we try to increase the \"siginal-to-noise\" while decreasing the computational expense. \n",
    "\n",
    "In our case, we will use the mean parameters for a starting point because it reduces the number of features to 5. Inuitively, mean values tend to be a good choice for measuring trends.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df_cancer, vars=['mean_radius','mean_texture','mean_perimeter','mean_area','mean_smoothness','mean_concave_points'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use Seaborn to color-code each datapoint based on the target value. This can help identify feature relationships that are the most indicative of a certain target value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.pairplot(df_cancer,hue='target', vars=['mean_radius','mean_texture','mean_perimeter','mean_area','mean_smoothness','mean_concave_points'])\n",
    "# Below is to allow the legend to use words instead of numbers. \n",
    "handles = g._legend_data.values()\n",
    "labels = ['Malignant','Benign'] \n",
    "g._legend.remove()\n",
    "g.fig.legend(handles=handles,labels=labels, loc='center right',ncol=1)\n",
    "g.fig.subplots_adjust(top=0.92,bottom=0.08,right=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, we might find it helpful to understand just how many values we have for each target label. A significant disparity can unintentionally bias our model. You may need to do resampling if your dataset is skewed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write code to bar plot the counts of target variable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color=B3A369><b>Feature Selection</b></font>\n",
    "\n",
    "Given the above, it seems fair to conclude that we have several values that are highly correlated, and that if we limit ourselves to just the mean values, we can reasonably represent the available data while maintaining efficiency. Since the perimeter and area are highly correlated with the radius, let's drop those two from the feature set.\n",
    "\n",
    "In preparation of our application, we can define the features and labels to use in our ML classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=['mean_radius','mean_concave_points','mean_smoothness','mean_concavity','mean_texture']\n",
    "labels=['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we want to define our feature columns for TensorFlow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = [tf.feature_column.numeric_column(key) for key in features]\n",
    "print(feature_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color=B3A369><b>Data Splitting</b></font>\n",
    "\n",
    "Next, we need to define our training and test datasets. The trick here is to designate some fraction of our total dataset to be used for training, and then use the remainder to validate our model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some classification problems can exhibit a large imbalance in the distribution of the target classes: for instance there could be several times more negative samples than positive samples. In such cases it is recommended to use the stratified sampling technique to ensure that relative class frequencies are approximately preserved in each train and validation fold. Here, 'random_state' can be set for reproducibility of results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we didn't reindex our dataframe, we can see the original row labels and confirm that the order is different:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "training_features,testing_features,training_labels,testing_labels=train_test_split(df_cancer[features],df_cancer[labels],test_size=0.2,random_state=1,stratify=df_cancer[labels])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we can verify the content of the training and test data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and see that the indices for the targets match those of the features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we build our training set from the other portion of randomized_data and confirm the same about its indices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color=B3A369><b>Feature Scaling</b></font>\n",
    "\n",
    "One thing that may immediately jump out is the variation in scale of the values for the different features. This can cause a few issues in our analysis if we are not careful:\n",
    "\n",
    "1. Some algorithms may not function when the scale of features is wildly different. For example, if a Euclidean distance is calculated, the larger feature may completely dominate the calculation.\n",
    "2. Gradient descent can converge more quickly if features are normalized, which can aid in training time.\n",
    "3. If regularization is used as part of the loss function, feature scaling is important to ensure that coefficients are penalized properly.\n",
    "\n",
    "Scikit-learn has built-in functionality that can perform our scaling and put all values in the range 0 to 1. Be careful not to scale the target too!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "training_features_scaled = scaler.fit_transform(training_features)\n",
    "testing_features_scaled = scaler.transform(testing_features) #Note only tansform for test set\n",
    "print(training_features_scaled.shape)\n",
    "print(training_features_scaled)\n",
    "print(testing_features_scaled.shape)\n",
    "print(testing_features_scaled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> It is important that you do feature scaling after data split, to avoid information leakage!</b> In fact, if you want to be extra careful, you should do data exploration only on the training set after the split.\n",
    "\n",
    "<i>Normalization vs Standardization:</i> Normalizing achieves a common scale used for multivariate analysis. Standarding achieves 0 mean and unit variace used for algorithms assumind Gaussian distribution (Ex: LDA and QDA).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color=B3A369><u><b>6. Select ML Algorithm and Train</b></u></font>\n",
    "\n",
    "There are many models that can be used to attempt to solve the problem of classifying whether the cancer is benign or malignant. In this example, we will use a neural network; which is a mathematical model that is inspired by how brains use.\n",
    "\n",
    "The strength of neural networks has been shown in the ability of these algorithms to excel in certain problems, especially classification. In the case of this problem, there is a deep pattern that is inside the set of data and the cancer outcome (otherwise, how would the physician's determination be better than a random determination). It seems like a fruitiful approach to develop neural network to classify each patient's data in terms of malignant or benign. \n",
    "\n",
    "<font size=4 color=B3A369><b>Neural Networks</b></font>\n",
    "\n",
    "Neural networks are a type of machine learning algorithm that are inspired by neurons in the human brain. Similar to neurons in the brains, neural networks are formed by interconnecting neurons that interact with each other. Each neuron takes input, does some simple alogrithm to it, and then passes an output to the next neuron.\n",
    "\n",
    "Let us look at a perceptron; that is, a single layer neural network. \n",
    "\n",
    "The *perceptron* is a mathematical function that takes a set of inputs, performs some operation, and outputs the result. In this case,\n",
    "$$ y = \\sum_{i} w_{i}x{i} + w_0,$$\n",
    "where $w_i$ is the weight of the perceptron and $w_0$ is the bias. Note that this is the form of a line (plane,hyperplane,...) The weights are used to determine the importance of the of that component and the bias shifts the activation function curve up and down. \n",
    "\n",
    "The results of the perceptron acting on the inputs, will be input into the activation function, which will determine how to classify the set. \n",
    "\n",
    "<font size=4 color=B3A369><b>Architecture of Neural Networks</b></font>\n",
    "\n",
    "A deep neural network consists of \n",
    "* An input layer \n",
    "* Any number of hidden layers (these are called hidden because the external observe does not see the output)\n",
    "* An output layer\n",
    "* A set of weights and bias between each layer $\\{w_i\\}, \\{b_i\\}$\n",
    "* An activation function for each layer, $\\sigma$\n",
    "\n",
    "<img src='image/neural_network_1.png'>\n",
    "\n",
    "<font size=4 color=B3A369><b>Training Process</b></font>\n",
    "\n",
    "Each iteration of the training process consists of the following steps:\n",
    "1. Calculating the predicted output $\\hat{y}$, known as _*Feedforward*_\n",
    "2. Updating the weights and biases, known as _*Backpropagation*_\n",
    "\n",
    "Schematicially, this can be illustated as \n",
    "<img src='image/nn_iteration.png'>\n",
    "\n",
    "<font size=3 color=B3A369><b>Feedforward</b></font>\n",
    "\n",
    "The forward motion is quite simply the calculation of the function in series, that is the the sum of the products of the weights and activations that lead to the neuron. So we are moving forward in the network. \n",
    "\n",
    "The loss function comes into play at this point, since we must determine the \"goodness\" of our performance.\n",
    "There are many possibilities to use for the *loss* function, such as the familar *sum-of-squares error*\n",
    "$$ \\mathrm{loss} = \\sum_{i=1}^n (y-\\hat{y})^2$$\n",
    "\n",
    "<font size=3 color=B3A369><b>Backpropagation</b></font>\n",
    "\n",
    "As we measure the error of our prediction, we can now find a way to use the error to improve the network, if desired. This is termed *backpropagation*. We work away back to update the weights and biases for the neurons. \n",
    "\n",
    "Minimization of the error function is how this optimization. There are multiple methods to optimize these multiple dimension functions, a popular one method may be to use the derviative of the loss function to determine the path of greatest decrease as in *gradient descent*.\n",
    "\n",
    "<font size=4 color=B3A369><b>Hyperparameters</b></font>\n",
    "\n",
    "*Hyperparameters* are the *variables which determine the network structure* and *how the network is trained*. Examples that effect the *learning rate* are *epoch*, *batches*, and *iterations*. These are important parameters that are not learned by the network so they must be specified by the model designer. \n",
    "\n",
    "An *epoch* is when an entire training dataset is passed forward and backward through the network *once*. It is at the end of an epoch that parameters (weights and biases) have updated. In short (batch_size * number_iterations >= number_data)\n",
    "\n",
    "An *iteration* is the number of *batches* needed to complete one epoch.\n",
    "\n",
    "In some cases, the dataset will need to be divided into *batches* in order to fit everything in memory in order complete the calculations. Many ML frameworks natively support this with batches, but sometimes you may have to manually specify them.\n",
    "\n",
    "<font size=4 color=B3A369><b>Lets Try it Out - Model Selection and Training</b></font>\n",
    "\n",
    "For our initial attempt, lets define a DNN Classifier with 2 hidden layers, and 2 dropout layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
    "\n",
    "#Fixing the seed for random number generators\n",
    "np.random.seed(40)\n",
    "import random\n",
    "random.seed(40)\n",
    "tf.random.set_seed(40)\n",
    "\n",
    "# we will be adding the layers sequentially\n",
    "model_1 = Sequential()\n",
    "\n",
    "# first hidden layer with 128 neurons and relu activation function, the input shape tuple denotes number of independent variables\n",
    "model_1.add(Dense(128, activation='relu', input_shape=(5,)))\n",
    "\n",
    "# we will be switching 20% of neurons randomly at each iteration to avoid overfitting\n",
    "model_1.add(Dropout(0.2))\n",
    "\n",
    "# second hidden layer with 64 neurons and relu activation function\n",
    "model_1.add(Dense(64, activation='relu'))\n",
    "\n",
    "# we will be switching 10% of neurons off randomly at each iteration to avoid overfitting\n",
    "model_1.add(Dropout(0.1))\n",
    "\n",
    "# output layer with only one neuron and sigmoid as activation function will give the probability of students getting admitted into UCLA  \n",
    "model_1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_1.compile(loss = 'binary_crossentropy', optimizer='adamax', metrics=['accuracy'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write code to summarize the model for inspection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_1 = model_1.fit(training_features_scaled, \n",
    "                    training_labels,\n",
    "                    validation_split=0.1, \n",
    "                    epochs=50, \n",
    "                    verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_1.history['accuracy'])\n",
    "plt.plot(history_1.history['val_accuracy'])\n",
    "plt.title('Accuracy vs Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Dropout layers achieve regularization required to avoid overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color=B3A369><u><b>7. Test Model</b></u></font>\n",
    "\n",
    "The model can make two types of wrong predictions:\n",
    "1. Predicting a patient has cancer when he/she doesn't\n",
    "2. Predicting a patient does not have cancer when he/she does.\n",
    "\n",
    "Which case is more important? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.evaluate(testing_features_scaled, testing_labels, verbose = 1)\n",
    "#Write code to do predictions on the test data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(classification_report(testing_labels, test_pred))\n",
    "cm = confusion_matrix(testing_labels, test_pred)\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.heatmap(cm, annot=True,  fmt='.0f', xticklabels=['Malignant', 'Benign'], yticklabels=['Malignant', 'Benign'])\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our accuracy is pretty high for a first shot!\n",
    "\n",
    "So how do we improve our model? There are multiple approaches we can consider:\n",
    "- Try different optimizer functions\n",
    "- Increase hidden layers\n",
    "- Change activiation functions\n",
    "- Increase number of neurons\n",
    "- Weight initialization\n",
    "- More data\n",
    "- Change learning algorithm parameters\n",
    "- Change our algorithm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> <font size=5 > [Please provide feedback!](https://gatech.co1.qualtrics.com/jfe/form/SV_55uzMYLufTuiLch) \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:app-of-ml]",
   "language": "python",
   "name": "conda-env-app-of-ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
